---
layout: post
title: 吴恩达机器学习记录2 单变量线性回归实战(octave)
date: 2020-3-23 14:32:00
categories:  机器学习
---

## 1. 数据
ex1data1.txt
看看数据：
数据有97条，第一列为x,第二列为y

```java
>> data =load("ex1data1.txt");
>> size(data)
ans =

   97    2

>> plot(data(:,1),data(:,2),"rx")
>>
```

<img src="https://raw.githubusercontent.com/QuietListener/quietlistener.github.io/master/images/20200323-lr-octave1.jpg" width="500"> 


## 2. 使用 批量梯度下降(batch gradient descent) 拟合。

### 1. 梯度下降算法代码
```java

function [theta,history_theta] = gradientDescent1(X, y, theta, alpha, iterations)  
%X为训练数据的输入值，y为标记的值，alpha为梯度下降的速率，  iterations为迭代次数
m = length(y) %训练数据个数
history_theta = zeros(m,2); %记录theta的变化
for i = 1:iterations %更新theta
  h = X * theta - y;
  theta(1) = theta(1) - alpha / m * sum(h);       
  theta(2) = theta(2) - alpha / m * sum(h.* X(:,2));
  %disp(sprintf('i= %d (%0.2f,%0.2f)',i,theta(1),theta(2)))

  %记录当前theta 
  history_theta(i,1) = theta(1);
  history_theta(i,2) = theta(2);
end
  
```


### 2. 准备数据并拟合
```java
iterations =  1500 %最多迭代次数
>> theta = [1;1]

theta =

   1
   1

>> alpha = 0.01; %递归下降速率

>> m = length(y)

m =  97
>> X = [ones(m,1),data(:,1)]; %训练数据X
>> y = data(:,2); %训练数据y

>> [theta,history_theta] = gradientDescent1(X, y, theta, alpha, iterations); %梯度下降拟合求参数 theta1 和 theta2

m =  97
>> theta %得到的曲线为 y = -3.5708x+1.1604
theta =

  -3.5708
   1.1604

>>
>> plot(data(:,1),data(:,2),"rx") %画数据图
>> hold on;
>> plot(X(:,2),theta(1)+theta(2)*X(:,2),"-") %画拟合图
```


<img src="https://raw.githubusercontent.com/QuietListener/quietlistener.github.io/master/images/20200323-lr-octave2.jpg" width="500"> 


### 3. 化代价函数的可视化

1. 代价函数(cost function)
**参数为theta时候的平局损失情况**

```java
function J = costFunctionJ(X,y,theta)
  m = length(y);
  J = sum((X*theta - y).^2) / (2*m);
```

2. 绘制参数为theta0 theta1的可是函数

x轴为theta0，y轴为theta1,z轴为**cost(代价)**
```java
>> theta0_vals = linspace(-10,10,100);
>> theta1_vals = linspace(-1,5,100);
>> J_vals = zeros(length(theta0_vals), length(theta1_vals));
>>  for i = 1:length(theta0_vals)
for j = 1:length(theta1_vals)
theta_point = [theta0_vals(i);theta1_vals(j)];
J_vals(i, j) = costFunctionJ(X,y,theta_point);
end
end
>> surf(theta0_vals,theta1_vals,J_vals);
>> surfc(theta0_vals,theta1_vals,J_vals);
>> colorbar
>> xlabel('\theta_0');
>> ylabel('\theta_1');

```

<img src="https://raw.githubusercontent.com/QuietListener/quietlistener.github.io/master/images/20200323-lr-octave4.jpg" width="500"> 


### 4. 绘制等高线

```java

>> contour(theta0_vals, theta1_vals, J_vals, logspace(-2, 3, 20));
>>  xlabel('\theta_0');
>>  ylabel('\theta_1');
>> hold on;
>> plot(theta(1),theta(2),"rx");
>>
```

<img src="https://raw.githubusercontent.com/QuietListener/quietlistener.github.io/master/images/20200323-lr-octave3.jpg" width="500"> 




