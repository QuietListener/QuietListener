---
layout: post
title:  kafka分而治之解决一个耗时异步接口问题
date:   2019-7-1 14:32:00
categories: kafka
---

#### 1.背景和问题
线上有一个功能，在学习一本书的时候导入其他书已经学习的单词，比如用户已经学了4级单词，然后学习6级，可以将4级和6级单词的交集中已学单词导入进来，这样用户就不用重复学一遍已学单词了。但是有些用户学习了很多单词，需要导入的单词量非常大，大的有大于4000多个。老逻辑是将要导入的单词异步发送到mq(公司自己写的一个mq，没有kafka好用)，然后让客户端等待一段时间(5秒)。这样就造成了一个问题。客户端等5秒时间不足以将3000+个单词存放数据库，并更新相关数据。测试后发现数据一致需要20秒以上，让用户等待20多秒也是不现实的。所有经常出现了告诉用户能导入2000个但是用户实际上只导入了几百个。好在大部分用户导入单词不到1000个，对这个问题不太敏感，所以就一直没有去解决(老逻辑使用自己写的mq，要解决不容易)。

#### 2.解决
 公司后台微服务化改造(springboot),新系统重构的时候没有注意到，也出现了这个问题。好在新系统重构，mq使用的是kafka,这个逻辑的topic分了30个partition。
 **老逻辑:**
 所有学习记录一起提交到mq
 ```
//提交到mq，doneRecords是学习记录
 studyRecordSubmitService.submitMergeRecord(userId, book_id, doneRecords); 
 ```

 **新逻辑:**
 分批，每批100个提交到mq
 ```
     //每批100个提交到mq
    int batchSize = 100;
    for (int i = 0; i < doneRecords.size(); i += batchSize) {
        int from = i;
        int to = from + batchSize;
        if (to > doneRecords.size()) {
            to = doneRecords.size();
        }
        List<DoneRecord> partition = doneRecords.subList(from, to);
        //提交到mq，提交一个批次
        studyRecordSubmitService.submitMergeRecord(userId, book_id, partition);
    }
 ```
 这样如果有3000个record，分成30个批次，几乎同时提价到mq，**而每个批次都发送到不同的partion(kafka的并行最小单位是partition)，可以并行计算。所以理论上加速了30倍。** 用户等待5秒以内就能将数据入库并修改相应的状态。
 **重要的是代码逻辑改动非常小。**