---
layout: post
title:  记一次分库扩容
date:   2019-8-20 14:32:00
categories: java web servlet
---
# 1.背景
1.线上学习记录使用的阿里云服务，一共有9个mysql库，按理说每个库1500万个用户，每个库的机器都是4核8G,硬盘1.95T，前几天收到报警，一个库(**A1**)容量已经达到1.85了。以前扩容阿里云操作很方便，直接扩大。当硬盘达到2T的时候，再次扩容只能到3T，而且只能买16核64G的机器，价格也要涨到8000多一个月，现在的4核8G的机器才2000多一个月。  

2. 和同事商量了一下，还是应该为公司省钱，再买一台4核8G+2T硬盘的机器，扩容。每年一台机器省4万8千块钱。


# 2.现状
**1. 数据库A1有1600万用户数据。**
**2. 数据里有3种表：**

>   **1.** 一种是按用户id垂直划分的,每个表50000个用户，表名为"record_t#{userId/500000}"，从**record_t999**到**record_t1227** 
>   **2.** 另一种是按用户id取摸，表名为"extra_t#{userId%10}",从**extra_t0**到**extra_t9** 
>   **3.** 一些公共读写的表，比如 inc_word_count_by_book,这个表存放用户增长的词汇量。

**3. record_t这类表占了绝大部分的存储，extra_t 表占用存储较少。**
**4. 有两类服务，一类只读，一类读写。**
**5. 读写服务的数据来自前端的一个kafka消息队列。**

 下面是一个当前架构图  
 ![部署](https://raw.githubusercontent.com/QuietListener/quietlistener.github.io/master/images/extend-db1.jpg)


# 3.方案
**1. 我们决定买一台一模一样的机器(A2)，让A1的数据同步到A2。最后让A2的数据追上A1的数据.保存很小时间的的不一致(5秒以内)。**
**2. 然后再把用户按照800万+800万分分别分到A1和A2上。**
**3. 在A1和A2上删除 另外800万用户的表(drop table)，释放出空间。**

# 4.问题
## 1. 按用户id取模的问题
record_t这种表迁移很简单，比如讲 record_t1100到record_t1227表同步到新库就好了，但是取模的表extra_t就不好按用户id来迁移了。
**解决办法：**只删除record_t表(drop table record_txx)，不删除extra_t表(本来占用空间也很少)

## 2. 主键冲突
inc_word_count_by_book 存在都在读写操作。当分库后应用对A1和A2同时进行读写的时候，容易出现主键冲突。  
1. 例如A1写了一调记录 比如(123,{"aa":bb}) 123是主键，
2. A2已经存在一条记录(123,{"aa":cc})
3. A1同步到A2时候就出现主键冲突  
**解决办法：**  停止上游kafka写入服务，让程序消费完kafka里的数据，让写服务无数据可写，也就不会出现冲突了。 
## 3. 服务重启顺序
1. 先重启读服务
2. 后重启读写服务



